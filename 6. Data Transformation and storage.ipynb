{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "134af2a5-b808-41c5-820e-8d0c3dfee118",
   "metadata": {},
   "source": [
    "### Data Transformation and Storage Script\n",
    "\n",
    "#### Overview\n",
    "This script processes and stores the latest customer churn data by performing the following steps:\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. Fetch Latest Data from S3\n",
    "- Identifies the most recent **processed train** and **API data** files in S3.\n",
    "- Downloads them to a local temporary folder.\n",
    "\n",
    "2. Apply Transformations\n",
    "- **Normalization & Scaling:** \n",
    "  - `CreditScore`, `Age`, `Balance`, and `EstimatedSalary` are normalized or standardized.\n",
    "- **Feature Engineering:** \n",
    "  - `BalancePerProduct` = `Balance` / `NumOfProducts`\n",
    "  - Missing values in `BalancePerProduct` are set to 0.\n",
    "\n",
    "3. Save and Upload\n",
    "- Saves transformed files locally in the **transformed_data/** folder.\n",
    "- Uploads the transformed files back to **S3 (transformed_data/ folder).**\n",
    "\n",
    "4. Store in PostgreSQL with Versioning\n",
    "- Appends transformed data to:\n",
    "  - **`transformed_train_data`** (for training).\n",
    "  - **`transformed_api_data`** (for inference).\n",
    "- Includes a **timestamp-based version** for tracking.\n",
    "\n",
    "#### Final Output\n",
    "- **Transformed data is stored in PostgreSQL, versioned, and uploaded to S3.**  \n",
    "**Process completed successfully!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "138d32f7-f78d-4e37-92b3-4cae7bc2110d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data transformation, storage, and versioning completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# uploads data in Postgres and Transformed folder in S3\n",
    "import os\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "from datetime import datetime\n",
    "\n",
    "# AWS S3 Configuration\n",
    "S3_BUCKET = \"dmml-bank-churn-data\"\n",
    "S3_PROCESSED_FOLDER = \"processed_data/\"\n",
    "S3_TRANSFORMED_FOLDER = \"transformed_data/\"\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "# PostgreSQL Configuration\n",
    "PASSWORD = quote_plus(\"131412aA@\")  # Properly encode special characters\n",
    "DB_URI = f\"postgresql+psycopg2://postgres:{PASSWORD}@localhost:5432/bank_churn\"\n",
    "engine = create_engine(DB_URI)\n",
    "\n",
    "# Local storage paths\n",
    "LOCAL_TRANSFORMED_FOLDER = \"transformed_data/\"\n",
    "LOCAL_TEMP_FOLDER = os.path.join(os.getcwd(), \"temp\")\n",
    "os.makedirs(LOCAL_TRANSFORMED_FOLDER, exist_ok=True)\n",
    "os.makedirs(LOCAL_TEMP_FOLDER, exist_ok=True)\n",
    "\n",
    "# Function to get latest file from S3\n",
    "def get_latest_s3_file(prefix):\n",
    "    response = s3_client.list_objects_v2(Bucket=S3_BUCKET, Prefix=prefix)\n",
    "    files = [obj[\"Key\"] for obj in response.get(\"Contents\", [])]\n",
    "    return max(files, key=lambda x: x.split(\"_\")[-1]) if files else None\n",
    "\n",
    "# Fetch latest train and API data from S3\n",
    "latest_train_file = get_latest_s3_file(S3_PROCESSED_FOLDER + \"prepared_train_data_\")\n",
    "latest_api_file = get_latest_s3_file(S3_PROCESSED_FOLDER + \"prepared_api_data_\")\n",
    "\n",
    "# Download and load data\n",
    "def load_s3_csv(file_key):\n",
    "    if not file_key:\n",
    "        raise FileNotFoundError(\"No matching file found on S3.\")\n",
    "    local_file = os.path.join(LOCAL_TEMP_FOLDER, os.path.basename(file_key))\n",
    "    s3_client.download_file(S3_BUCKET, file_key, local_file)\n",
    "    return pd.read_csv(local_file)\n",
    "\n",
    "df_train = load_s3_csv(latest_train_file)\n",
    "df_api = load_s3_csv(latest_api_file)\n",
    "\n",
    "# Apply transformations (excluding 'Exited' for API data)\n",
    "def transform_data(df, is_api=False):\n",
    "    df[\"CreditScore\"] = df[\"CreditScore\"].apply(lambda x: (x - df[\"CreditScore\"].min()) / (df[\"CreditScore\"].max() - df[\"CreditScore\"].min()))\n",
    "    df[\"Age\"] = (df[\"Age\"] - df[\"Age\"].mean()) / df[\"Age\"].std()\n",
    "    df[\"Balance\"] = (df[\"Balance\"] - df[\"Balance\"].mean()) / df[\"Balance\"].std()\n",
    "    df[\"EstimatedSalary\"] = (df[\"EstimatedSalary\"] - df[\"EstimatedSalary\"].mean()) / df[\"EstimatedSalary\"].std()\n",
    "    \n",
    "    # Derived feature: Balance per Product\n",
    "    df[\"BalancePerProduct\"] = df[\"Balance\"] / df[\"NumOfProducts\"]\n",
    "    df[\"BalancePerProduct\"] = df[\"BalancePerProduct\"].fillna(0)\n",
    "    \n",
    "    if is_api:\n",
    "        df.drop(columns=[\"Exited\"], errors='ignore', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train_transformed = transform_data(df_train)\n",
    "df_api_transformed = transform_data(df_api, is_api=True)\n",
    "\n",
    "# Save locally\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "train_local_file = os.path.join(LOCAL_TRANSFORMED_FOLDER, f\"transformed_train_data_{timestamp}.csv\")\n",
    "api_local_file = os.path.join(LOCAL_TRANSFORMED_FOLDER, f\"transformed_api_data_{timestamp}.csv\")\n",
    "df_train_transformed.to_csv(train_local_file, index=False)\n",
    "df_api_transformed.to_csv(api_local_file, index=False)\n",
    "\n",
    "# Upload back to S3 with correct folder\n",
    "def upload_to_s3(file_path, folder):\n",
    "    if os.path.exists(file_path):\n",
    "        s3_client.upload_file(file_path, S3_BUCKET, folder + os.path.basename(file_path))\n",
    "    else:\n",
    "        print(f\"⚠️ File not found for upload: {file_path}\")\n",
    "\n",
    "upload_to_s3(train_local_file, S3_TRANSFORMED_FOLDER)\n",
    "upload_to_s3(api_local_file, S3_TRANSFORMED_FOLDER)\n",
    "\n",
    "# Store in PostgreSQL with versioning\n",
    "def store_in_sql(df, table_name):\n",
    "    df[\"version\"] = timestamp\n",
    "    df.to_sql(table_name, engine, if_exists=\"append\", index=False)\n",
    "\n",
    "store_in_sql(df_train_transformed, \"transformed_train_data\")\n",
    "store_in_sql(df_api_transformed, \"transformed_api_data\")\n",
    "\n",
    "print(\"✅ Data transformation, storage, and versioning completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9985916-c8cf-4b79-8a77-71275383cf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               table_name          version\n",
      "0    transformed_api_data  20250311_121740\n",
      "1  transformed_train_data  20250311_121740\n",
      "2    transformed_api_data  20250310_232359\n",
      "3  transformed_train_data  20250310_232359\n",
      "4  transformed_train_data  20250310_231953\n",
      "5    transformed_api_data  20250310_231953\n",
      "6  transformed_train_data  20250310_144945\n",
      "7    transformed_api_data  20250310_144945\n",
      "8  transformed_train_data  20250310_143250\n",
      "9    transformed_api_data  20250310_143250\n"
     ]
    }
   ],
   "source": [
    "# Create a database connection\n",
    "conn = engine.connect()\n",
    "\n",
    "# Query to get unique versions from both tables\n",
    "query = \"\"\"\n",
    "SELECT 'transformed_train_data' AS table_name, version FROM transformed_train_data\n",
    "UNION\n",
    "SELECT 'transformed_api_data' AS table_name, version FROM transformed_api_data\n",
    "ORDER BY version DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and fetch results\n",
    "df_versions = pd.read_sql(query, conn)\n",
    "\n",
    "# Display the versions\n",
    "print(df_versions)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b7f47-0545-4f56-b8cb-77b625ab0bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b8ac81-d18c-4781-aa52-e94d707a8c04",
   "metadata": {},
   "source": [
    "#### Final Data Preparation and EDA Script\n",
    "  - **AWS S3 Configuration**\n",
    "    - Define bucket and prefixes\n",
    "    - Set up local directories\n",
    "    - Initialize S3 client\n",
    "\n",
    "  - **Fetching Latest Data**\n",
    "    - Retrieve latest train and API files from S3\n",
    "\n",
    "  - **Downloading Data**\n",
    "    - Load CSV files from S3 into Pandas DataFrames\n",
    "\n",
    "  - **Data Preprocessing**\n",
    "    - Encode Categorical Variables\n",
    "    - Handle Outliers using IQR Method\n",
    "\n",
    "  - **Exploratory Data Analysis (EDA)**\n",
    "    - Generate Statistical Summary\n",
    "    - Save and Upload EDA Reports\n",
    "    - Generate and Upload Visualizations\n",
    "      - **Histograms**\n",
    "        - Credit Score\n",
    "        - Age\n",
    "        - Balance\n",
    "        - Number of Products\n",
    "      - **Box Plots**\n",
    "        - Credit Score\n",
    "        - Age\n",
    "        - Balance\n",
    "      - **Correlation Heatmap**\n",
    "\n",
    "  - **Saving and Uploading Processed Data**\n",
    "    - Save processed data locally\n",
    "    - Upload processed data to S3\n",
    "\n",
    "  - **Main Execution Flow**\n",
    "    - Process Train Data\n",
    "    - Process API Data\n",
    "    - Execute all steps sequentially\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc53dd0-6934-4da7-b101-7ff1a9e93e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import boto3\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------------------- AWS S3 Configuration ----------------------\n",
    "S3_BUCKET = \"dmml-bank-churn-data\"\n",
    "S3_PREFIX = \"raw_data/\"\n",
    "OUTPUT_PREFIX = \"processed_data/\"\n",
    "EDA_PREFIX = \"eda_reports/\"\n",
    "LOCAL_DIR = \"C:/Users/LENOVO/Documents/Study/M.Tech Data Science Pilani/Sem-2/Data Management for Machine Learning-ZG529/Assignment-1/Files\"\n",
    "LOCAL_EDA_DIR = os.path.join(LOCAL_DIR, \"EDA_Reports\")\n",
    "LOCAL_PROCESSED_DIR = os.path.join(LOCAL_DIR, \"Processed_Data\")\n",
    "\n",
    "os.makedirs(LOCAL_PROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs(LOCAL_EDA_DIR, exist_ok=True)\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "def get_latest_s3_files():\n",
    "    \"\"\"Fetch latest train and API files from S3 based on timestamps.\"\"\"\n",
    "    response = s3_client.list_objects_v2(Bucket=S3_BUCKET, Prefix=S3_PREFIX)\n",
    "    \n",
    "    if \"Contents\" not in response:\n",
    "        return None, None\n",
    "    \n",
    "    files = sorted(response[\"Contents\"], key=lambda x: x[\"LastModified\"], reverse=True)\n",
    "    \n",
    "    train_file = next((f[\"Key\"] for f in files if \"train\" in f[\"Key\"].lower()), None)\n",
    "    api_file = next((f[\"Key\"] for f in files if \"api\" in f[\"Key\"].lower()), None)\n",
    "    \n",
    "    return train_file, api_file\n",
    "\n",
    "def download_s3_file(file_key):\n",
    "    \"\"\"Download CSV file from S3 and return as Pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        obj = s3_client.get_object(Bucket=S3_BUCKET, Key=file_key)\n",
    "        df = pd.read_csv(obj[\"Body\"])\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error downloading {file_key}: {e}\")\n",
    "        return None\n",
    "\n",
    "def encode_categorical(df):\n",
    "    \"\"\"Encode categorical variables.\"\"\"\n",
    "    df[\"Gender\"] = df[\"Gender\"].map({\"Male\": 0, \"Female\": 1})\n",
    "    df = pd.get_dummies(df, columns=[\"Geography\"], prefix=\"Geography\", drop_first=False)\n",
    "    return df\n",
    "\n",
    "def handle_outliers(df):\n",
    "    \"\"\"Detect and handle outliers using IQR method.\"\"\"\n",
    "    num_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts']\n",
    "    \n",
    "    for col in num_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "        df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def perform_eda(df):\n",
    "    \"\"\"Generate statistics, visualizations, and a correlation heatmap for EDA.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    report_file = os.path.join(LOCAL_EDA_DIR, f\"eda_report_{timestamp}.csv\")\n",
    "    \n",
    "    # Generate and save statistics\n",
    "    stats = df.describe()\n",
    "    stats.to_csv(report_file, index=True)\n",
    "    logging.info(f\"‚úÖ EDA report saved locally: {report_file}\")\n",
    "\n",
    "    # Upload EDA report to S3\n",
    "    s3_key = f\"{EDA_PREFIX}eda_report_{timestamp}.csv\"\n",
    "    csv_buffer = StringIO()\n",
    "    stats.to_csv(csv_buffer, index=True)\n",
    "    s3_client.put_object(Bucket=S3_BUCKET, Key=s3_key, Body=csv_buffer.getvalue())\n",
    "    logging.info(f\"‚úÖ EDA report uploaded to S3: {s3_key}\")\n",
    "\n",
    "    # Generate EDA Plots\n",
    "    plot_types = [\n",
    "        (\"Distribution of Credit Score\", \"CreditScore\", \"hist\"),\n",
    "        (\"Distribution of Age\", \"Age\", \"hist\"),\n",
    "        (\"Distribution of Balance\", \"Balance\", \"hist\"),\n",
    "        (\"Distribution of NumOfProducts\", \"NumOfProducts\", \"hist\"),\n",
    "        (\"Boxplot of Credit Score\", \"CreditScore\", \"box\"),\n",
    "        (\"Boxplot of Age\", \"Age\", \"box\"),\n",
    "        (\"Boxplot of Balance\", \"Balance\", \"box\"),\n",
    "    ]\n",
    "    \n",
    "    for title, column, plot_type in plot_types:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        if plot_type == \"hist\":\n",
    "            sns.histplot(df[column], kde=True, bins=30)\n",
    "        elif plot_type == \"box\":\n",
    "            sns.boxplot(x=df[column])\n",
    "        plt.title(title)\n",
    "        plot_path = os.path.join(LOCAL_EDA_DIR, f\"{column}_{plot_type}_{timestamp}.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        logging.info(f\"‚úÖ EDA plot saved locally: {plot_path}\")\n",
    "\n",
    "        # Upload EDA plot to S3\n",
    "        with open(plot_path, \"rb\") as img_file:\n",
    "            s3_client.put_object(Bucket=S3_BUCKET, Key=f\"{EDA_PREFIX}{column}_{plot_type}_{timestamp}.png\", Body=img_file)\n",
    "        logging.info(f\"‚úÖ EDA plot uploaded to S3: {EDA_PREFIX}{column}_{plot_type}_{timestamp}.png\")\n",
    "\n",
    "    # Generate Correlation Heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Select only numerical columns for correlation\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Compute correlation matrix\n",
    "    corr_matrix = numeric_df.corr()\n",
    "\n",
    "    # Plot heatmap\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "    plt.title(\"Feature Correlation Heatmap\")\n",
    "    \n",
    "    heatmap_path = os.path.join(LOCAL_EDA_DIR, f\"correlation_heatmap_{timestamp}.png\")\n",
    "    plt.savefig(heatmap_path)\n",
    "    plt.close()\n",
    "    logging.info(f\"‚úÖ Correlation heatmap saved locally: {heatmap_path}\")\n",
    "\n",
    "    # Upload heatmap to S3\n",
    "    with open(heatmap_path, \"rb\") as img_file:\n",
    "        s3_client.put_object(Bucket=S3_BUCKET, Key=f\"{EDA_PREFIX}correlation_heatmap_{timestamp}.png\", Body=img_file)\n",
    "    logging.info(f\"‚úÖ Correlation heatmap uploaded to S3: {EDA_PREFIX}correlation_heatmap_{timestamp}.png\")\n",
    "\n",
    "def save_and_upload(df, filename_prefix):\n",
    "    \"\"\"Save processed data locally and upload to S3.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    local_path = os.path.join(LOCAL_PROCESSED_DIR, f\"{filename_prefix}_{timestamp}.csv\")\n",
    "    df.to_csv(local_path, index=False)\n",
    "    logging.info(f\"‚úÖ Processed data saved locally: {local_path}\")\n",
    "    \n",
    "    s3_key = f\"{OUTPUT_PREFIX}{filename_prefix}_{timestamp}.csv\"\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "    s3_client.put_object(Bucket=S3_BUCKET, Key=s3_key, Body=csv_buffer.getvalue())\n",
    "    logging.info(f\"‚úÖ Processed data uploaded to S3: {s3_key}\")\n",
    "\n",
    "def main():\n",
    "    train_file, api_file = get_latest_s3_files()\n",
    "    \n",
    "    if train_file:\n",
    "        logging.info(f\"üìÇ Found latest train file: {train_file}\")\n",
    "        train_df = download_s3_file(train_file)\n",
    "        perform_eda(train_df)  # Run EDA before encoding\n",
    "        train_df = encode_categorical(train_df)\n",
    "        train_df = handle_outliers(train_df)\n",
    "        save_and_upload(train_df, \"prepared_train_data\")\n",
    "    else:\n",
    "        logging.error(\"‚ùå No train data found.\")\n",
    "        return\n",
    "    \n",
    "    if api_file:\n",
    "        logging.info(f\"üìÇ Found latest API file: {api_file}\")\n",
    "        api_df = download_s3_file(api_file)\n",
    "        perform_eda(api_df)  # Run EDA before encoding\n",
    "        api_df = encode_categorical(api_df)\n",
    "        api_df = handle_outliers(api_df)\n",
    "        save_and_upload(api_df, \"prepared_api_data\")\n",
    "    else:\n",
    "        logging.error(\"‚ùå No API data found.\")\n",
    "        return\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
